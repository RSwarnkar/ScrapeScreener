{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b95b543-b497-433f-bf9d-95d104967229",
   "metadata": {},
   "source": [
    "# Scrape Screener\n",
    "## Jupyter notebook that scrapes stocks data from Screener.in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058cb0ff-b307-4e5a-9889-055c499f119b",
   "metadata": {},
   "source": [
    "* Sheet 1: Top Ratios \r\n",
    "* Sheet 2: Quarterly Results\r\n",
    "* Sheet 3: Profit & Loss\r\n",
    "* Sheet 4: Compounded Sales Growth\r\n",
    "* Sheet 5: Compounded Profit Growth\r\n",
    "* Sheet 6: Stock Price CAGR \r\n",
    "* Sheet 7: Return on Equity\r\n",
    "* Sheet 8: Balance Sheet\r\n",
    "* Sheet 9: Cash Flows\r\n",
    "* Sheet 10: Ratios\r\n",
    "* Sheet 11: Shareholdin\n",
    "ng Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248e3e6-7420-43c1-8e08-84de85234c66",
   "metadata": {},
   "source": [
    "### 1.1 Imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4abb2c-cb21-4644-b4e7-1dd4d2c2e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd \n",
    "import time\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720dfb60-5f2d-4a6a-872a-74825dd5791e",
   "metadata": {},
   "source": [
    ">  ⚠️ <span style=\"color:red\"> **Update the CSV File below to read as needed:**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777412cc-8a4d-45be-b7d6-4e5be88f8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For My Watchlisted stocks\n",
    "input_csv_file = \"../Input/\" + \"stocks-watchlisted.csv\"\n",
    "# For PSU stocks\n",
    "input_csv_file = \"../Input/\" + \"stocks-psu.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd031422-b1a4-4cd2-841c-406e2b1aa93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_file = \"../Input/\" + \"stocks-watchlisted.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e341645-7e6f-4859-9301-245d9582c803",
   "metadata": {},
   "source": [
    "### 1.2 Read Stock List: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86feab31-0ab8-4f9f-a717-bfa808e87503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screener Stock Symbol</th>\n",
       "      <th>Url Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526433</td>\n",
       "      <td>consolidated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532407</td>\n",
       "      <td>consolidated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>544021</td>\n",
       "      <td>consolidated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Screener Stock Symbol   Url Segment\n",
       "0                526433  consolidated\n",
       "1                532407  consolidated\n",
       "2                544021  consolidated"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(input_csv_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa675c-2860-4ac3-941a-9895210bab3a",
   "metadata": {},
   "source": [
    "### 1.3.1 Function that transforms Unordered list to dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b733e330-faa8-43d9-b08e-38b216b23443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvfy(lines):\n",
    "    import re\n",
    "\n",
    "    # Line - 0\n",
    "    if m := re.match(r\"Market Cap ₹ ([0-9,.-]+) Cr.\", lines[0]):\n",
    "        line_0 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_0 = \"NaN\"\n",
    "\n",
    "    # Line - 1\n",
    "    if m := re.match(r\"Current Price ₹ ([0-9,.-]+)\", lines[1]):\n",
    "        line_1 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_1 = \"NaN\"\n",
    "\n",
    "    # Line - 2a\n",
    "    if m := re.match(r\"High \\/ Low ₹ ([0-9,..-]+) \\/ ([0-9,.]+)\", lines[2]):\n",
    "        line_2a = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_2a = \"NaN\"\n",
    "\n",
    "    # Line - 2b\n",
    "    if m := re.match(r\"High \\/ Low ₹ ([0-9,.-]+) \\/ ([0-9,.]+)\", lines[2]):\n",
    "        line_2b = m.group(2).replace(',','')\n",
    "    else: \n",
    "        line_2b = \"NaN\"\n",
    "\n",
    "    # Line - 3\n",
    "    if m := re.match(r\"Stock P\\/E ([0-9,.-]+)\", lines[3]):\n",
    "        line_3 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_3 = \"NaN\"\n",
    "\n",
    "    # Line - 4\n",
    "    if m := re.match(r\"Book Value ₹ ([0-9,.-]+)\", lines[4]):\n",
    "        line_4 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_4 = \"NaN\"\n",
    "\n",
    "    # Line - 5\n",
    "    if m := re.match(r\"Dividend Yield ([0-9,.-]+) %\", lines[5]):\n",
    "        line_5 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_5 = \"NaN\"\n",
    "\n",
    "    # Line - 6\n",
    "    if m := re.match(r\"ROCE ([0-9,.-]+) %\", lines[6]):\n",
    "        line_6 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_6 = \"NaN\"\n",
    "\n",
    "    # Line - 7\n",
    "    if m := re.match(r\"ROE ([0-9,.-]+) %\", lines[7]):\n",
    "        line_7 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_7 = \"NaN\"\n",
    "\n",
    "    # Line - 8\n",
    "    if m := re.match(r\"Face Value ₹ ([0-9,.-]+)\", lines[8]):\n",
    "        line_8 = m.group(1).replace(',','')\n",
    "    else: \n",
    "        line_8 = \"NaN\"\n",
    "\n",
    "    x = [{\n",
    "    \"Market Cap in Cores Rupees\":line_0,\n",
    "    \"Current Price in Rupees\":line_1,\n",
    "    \"High in Rupees\":line_2a,\n",
    "    \"Low in Rupees\":line_2b,\n",
    "    \"Stock PE\":line_3,\n",
    "    \"Book Value in Rupees\":line_4,\n",
    "    \"Dividend Yield %\": line_5,\n",
    "    \"ROCE %\":line_6,\n",
    "    \"ROE %\":line_7,\n",
    "    \"Face Value in Rupees\":line_8,\n",
    "    }]\n",
    "\n",
    "    df = pd.DataFrame(x)\n",
    "\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8402cd1-6f6a-4fd3-a4ed-eb039e473a74",
   "metadata": {},
   "source": [
    "### 1.3.2 Scrape and create reports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7179adbf-405a-43b2-af6c-182e97a2a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Page for  526433\n",
      "Loading Page for  532407\n",
      "Loading Page for  544021\n",
      "Loading Page for  AARTIDRUGS\n",
      "Loading Page for  AARTIIND\n",
      "Loading Page for  AARTIPHARM\n",
      "Loading Page for  AARTISURF\n",
      "Loading Page for  ABB\n",
      "Loading Page for  ACC\n",
      "Loading Page for  ADANIENT\n",
      "Loading Page for  AFFLE\n",
      "Loading Page for  ALKYLAMINE\n",
      "Loading Page for  ANGELONE\n",
      "Loading Page for  ARE&M\n",
      "Loading Page for  ASAHIINDIA\n",
      "Loading Page for  ASHOKLEY\n",
      "Loading Page for  ASIANPAINT\n",
      "Loading Page for  ASTRAL\n",
      "Loading Page for  AXISBANK\n",
      "Loading Page for  BAJAJ-AUTO\n",
      "Loading Page for  BAJAJELEC\n",
      "Loading Page for  BAJAJFINSV\n",
      "Loading Page for  BAJFINANCE\n",
      "Loading Page for  BALAMINES\n",
      "Loading Page for  BATAINDIA\n",
      "Loading Page for  BEL\n",
      "Loading Page for  BERGEPAINT\n",
      "Loading Page for  BHARTIARTL\n",
      "Loading Page for  BOROLTD\n",
      "Loading Page for  BRITANNIA\n",
      "Loading Page for  BSE\n",
      "Loading Page for  CAMS\n",
      "Loading Page for  CAMPUS\n",
      "Loading Page for  CDSL\n",
      "Loading Page for  CENTUM\n",
      "Loading Page for  CGPOWER\n",
      "Loading Page for  COCHINSHIP\n",
      "Loading Page for  COFORGE\n",
      "Loading Page for  CONCOR\n",
      "Loading Page for  CYIENT\n",
      "Loading Page for  DABUR\n",
      "Loading Page for  DEEPAKNTR\n",
      "Loading Page for  DIVISLAB\n",
      "Loading Page for  DIXON\n",
      "Loading Page for  DMART\n",
      "Loading Page for  DRREDDY\n",
      "Loading Page for  EICHERMOT\n",
      "Loading Page for  ETHOSLTD\n",
      "Loading Page for  EXIDEIND\n",
      "Loading Page for  FINEORG\n",
      "Loading Page for  GMMPFAUDLR\n",
      "Loading Page for  GODREJPROP\n",
      "Loading Page for  GREENLAM\n",
      "Loading Page for  GREENPANEL\n",
      "Loading Page for  GRSE\n",
      "Loading Page for  HAL\n",
      "Loading Page for  HAPPSTMNDS\n",
      "Loading Page for  HAVELLS\n",
      "Loading Page for  HCLTECH\n",
      "Loading Page for  HDFCAMC\n",
      "Loading Page for  HDFCBANK\n",
      "Loading Page for  HDFCLIFE\n",
      "Loading Page for  HERITGFOOD\n",
      "Loading Page for  HEROMOTOCO\n",
      "Loading Page for  HINDUNILVR\n",
      "Loading Page for  HLEGLAS\n",
      "Loading Page for  HNDFDS\n",
      "Loading Page for  ICICIBANK\n",
      "Loading Page for  ICICIGI\n",
      "Loading Page for  ICICIPRULI\n",
      "Loading Page for  IDEAFORGE\n",
      "Loading Page for  IDFCFIRSTB\n",
      "Loading Page for  INDIGO\n",
      "Loading Page for  INDIGOPNTS\n",
      "Loading Page for  INFY\n",
      "Loading Page for  IRCON\n",
      "Loading Page for  IRCTC\n",
      "Loading Page for  IREDA\n",
      "Loading Page for  ITC\n",
      "Loading Page for  JIOFIN\n",
      "Loading Page for  JUBLFOOD\n",
      "Loading Page for  KALYANKJIL\n",
      "Loading Page for  KAYNES\n",
      "Loading Page for  KEI\n",
      "Loading Page for  KOTAKBANK\n",
      "Loading Page for  KPIGREEN\n",
      "Loading Page for  KPITTECH\n",
      "Loading Page for  KSCL\n",
      "Loading Page for  LALPATHLAB\n",
      "Loading Page for  LATENTVIEW\n",
      "Loading Page for  LT\n",
      "Loading Page for  LTIM\n",
      "Loading Page for  LTTS\n",
      "Loading Page for  LXCHEM\n",
      "Loading Page for  M&M\n",
      "Loading Page for  MANKIND\n",
      "Loading Page for  MAPMYINDIA\n",
      "Loading Page for  MARICO\n",
      "Loading Page for  MARUTI\n",
      "Loading Page for  MAZDOCK\n",
      "Loading Page for  METROBRAND\n",
      "Loading Page for  MOLDTECH\n",
      "Loading Page for  MOLDTKPAC\n",
      "Loading Page for  MOTHERSON\n",
      "Loading Page for  MTARTECH\n",
      "Loading Page for  MUFTI\n",
      "Loading Page for  MUTHOOTFIN\n",
      "Loading Page for  NAUKRI\n",
      "Loading Page for  NAVINFLUOR\n",
      "Loading Page for  NAZARA\n",
      "Loading Page for  NEOGEN\n",
      "Loading Page for  NESTLEIND\n",
      "Loading Page for  NETWEB\n",
      "Loading Page for  PAGEIND\n",
      "Loading Page for  PARAS\n",
      "Loading Page for  PERSISTENT\n",
      "Loading Page for  PIDILITIND\n",
      "Loading Page for  PIIND\n",
      "Loading Page for  POLYCAB\n",
      "Loading Page for  PRINCEPIPE\n",
      "Loading Page for  RAILTEL\n",
      "Loading Page for  RAYMOND\n",
      "Loading Page for  REDTAPE\n",
      "Loading Page for  RELAXO\n",
      "Loading Page for  RELIANCE\n",
      "Loading Page for  ROSSARI\n",
      "Loading Page for  ROUTE\n",
      "Loading Page for  RVNL\n",
      "Loading Page for  SBICARD\n",
      "Loading Page for  SBIN\n",
      "Loading Page for  SIEMENS\n",
      "Loading Page for  SONACOMS\n",
      "Loading Page for  SPICELEC\n",
      "Loading Page for  SRF\n",
      "Loading Page for  SUNPHARMA\n",
      "Loading Page for  TATACONSUM\n",
      "Loading Page for  TATAELXSI\n",
      "Loading Page for  TATAINVEST\n",
      "Loading Page for  TATAMOTORS\n",
      "Loading Page for  TATAPOWER\n",
      "Loading Page for  TATATECH\n",
      "Loading Page for  TCS\n",
      "Loading Page for  TECHM\n",
      "Loading Page for  TIINDIA\n",
      "Loading Page for  TITAGARH\n",
      "Loading Page for  TITAN\n",
      "Loading Page for  TORNTPHARM\n",
      "Loading Page for  TRENT\n",
      "Loading Page for  TVSMOTOR\n",
      "Loading Page for  UBL\n",
      "Loading Page for  UNITDSPR\n",
      "Loading Page for  UNOMINDA\n",
      "Loading Page for  VBL\n",
      "Loading Page for  VINATIORGA\n",
      "Loading Page for  MANYAVAR\n",
      "Loading Page for  VOLTAS\n",
      "Loading Page for  WESTLIFE\n",
      "Loading Page for  WIPRO\n",
      "Loading Page for  YASHO\n",
      "Loading Page for  ZENTEC\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "writer = None\n",
    "dir_path = \"../Output/RawReports-01/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"/\"\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    stock_symbol = row[\"Screener Stock Symbol\"]\n",
    "    url_segment = row[\"Url Segment\"]\n",
    "    if url_segment==\"consolidated\":\n",
    "        url =  \"https://www.screener.in/company/\"+stock_symbol+\"/consolidated/\"\n",
    "    else:\n",
    "        url =  \"https://www.screener.in/company/\"+stock_symbol+\"/\"\n",
    "    # print(url)\n",
    "    print(\"Loading Page for \",stock_symbol)\n",
    "    tables = pd.read_html(url)\n",
    "    time.sleep(1) # Seconds\n",
    "    \n",
    "    # Read the Top Ration. Top Ratios section is a List Item, not a table hence need \n",
    "    # to parse manually usiang bsoup \n",
    "    response = rq.get(url)\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Find the unordered list\n",
    "    ul = soup.find(\"ul#top-ratios\")  # You might need to use a more specific selector like ul.my-list\n",
    "    lines = []\n",
    "    for ul in soup.findAll('ul', id='top-ratios'):\n",
    "        for li in ul.findAll('li'):\n",
    "            li_parsed_text = li.text\n",
    "            li_parsed_text = re.sub('[\\s ]+', ' ', li_parsed_text)\n",
    "            li_parsed_text = li_parsed_text.strip()\n",
    "            #print(li_parsed_text)\n",
    "            lines.append(li_parsed_text)\n",
    "   \n",
    "    time.sleep(1) # Seconds\n",
    "    \n",
    "    # Get all Tables in separate dataframes\n",
    "    df_top_ratios               = csvfy(lines) # Call function\n",
    "    df_quaterly_results         = tables[0] # Quarterly Results\n",
    "    df_profit_n_loss            = tables[1] # Profit & Loss\n",
    "    df_compounded_sales_growth  = tables[2] # Compounded Sales Growth\n",
    "    df_compounded_profit_growth = tables[3] # Compounded Profit Growth\n",
    "    df_stock_price_cagr         = tables[4] # Stock Price CAGR\n",
    "    df_return_on_equity         = tables[5] # Return on Equity\n",
    "    df_balance_sheet            = tables[6] # Balance Sheet\n",
    "    df_cash_flows               = tables[7] # Cash Flows\n",
    "    df_ratios                   = tables[8] # Ratios\n",
    "    df_shareholding_pattern     = tables[9] # Shareholding Pattern\n",
    "    \n",
    "    # Cleanup table: Quarterly Results\n",
    "    df_quaterly_results.rename(columns={'Unnamed: 0':'Quarterly Results'}, inplace=True)\n",
    "    df_quaterly_results.replace(u\"\\u00A0\\+\", \"\", regex=True,inplace=True) \n",
    "    \n",
    "    # Cleanup table: Profit & Loss\n",
    "    df_profit_n_loss.rename(columns={'Unnamed: 0':'Profit and Loss'}, inplace=True)\n",
    "    df_profit_n_loss.replace(u\"\\u00A0\\+\", \"\", regex=True,inplace=True) \n",
    "\n",
    "    # Cleanup table: Compounded Sales Growth\n",
    "    df_compounded_sales_growth.replace(\":\", \"\", regex=True,inplace=True) \n",
    "    \n",
    "    # Cleanup table: Compounded Profit Growth\n",
    "    df_compounded_profit_growth.replace(\":\", \"\", regex=True,inplace=True) \n",
    "    \n",
    "    # Cleanup table: Stock Price CAGR\n",
    "    df_stock_price_cagr.replace(\":\", \"\", regex=True,inplace=True) \n",
    "    \n",
    "    # Cleanup table: Return on Equity\n",
    "    df_return_on_equity.replace(\":\", \"\", regex=True,inplace=True) \n",
    "    \n",
    "    # Cleanup table: Balance Sheet\n",
    "    df_balance_sheet.rename(columns={'Unnamed: 0':'Balance Sheet'}, inplace=True)\n",
    "    df_balance_sheet.replace(u\"\\u00A0\\+\", \"\", regex=True,inplace=True) \n",
    "    \n",
    "    # Cleanup table: Cash Flows\n",
    "    df_cash_flows.rename(columns={'Unnamed: 0':'Cash Flows'}, inplace=True)\n",
    "    df_cash_flows.replace(u\"\\u00A0\\+\", \"\", regex=True,inplace=True) \n",
    "    \n",
    "    # Cleanup table: Ratios\n",
    "    df_ratios.rename(columns={'Unnamed: 0':'Ratios'}, inplace=True)\n",
    "    \n",
    "    # Cleanup table: Shareholding Pattern\n",
    "    df_shareholding_pattern.rename(columns={'Unnamed: 0':'Shareholding Pattern'}, inplace=True)\n",
    "    df_shareholding_pattern.replace(u\"\\u00A0\\+\", \"\", regex=True,inplace=True)\n",
    "\n",
    "    df_top_ratios \n",
    "    \n",
    "    sheet_names = [\"Top Ratios\",\"Quarterly Results\", \"Profit & Loss\", \"Compounded Sales Growth\", \"Compounded Profit Growth\", \n",
    "                   \"Stock Price CAGR\", \"Return on Equity\", \"Balance Sheet\", \"Cash Flows\", \"Ratios\", \"Shareholding Pattern\"]\n",
    "    dataframes  = [df_top_ratios, df_quaterly_results, df_profit_n_loss , df_compounded_sales_growth, df_compounded_profit_growth, \n",
    "                   df_stock_price_cagr, df_return_on_equity, df_balance_sheet, df_cash_flows, df_ratios, df_shareholding_pattern]\n",
    "    \n",
    "    writer = pd.ExcelWriter(dir_path + stock_symbol + \".xlsx\" , engine='xlsxwriter')\n",
    "    for i, frame in enumerate(dataframes):\n",
    "        frame.to_excel(writer, sheet_name = sheet_names[i], index=False)\n",
    "    writer.close()\n",
    "    writer.handles = None\n",
    "\n",
    "print(\"All Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758791f2-b77e-46bc-a99d-cf01bee80a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone\n"
     ]
    }
   ],
   "source": [
    "if 'consolidated' not in 'https://www.screener.in/company/DMART/': \n",
    "   print('Standalone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8989e633-b9c2-4f74-8e88-54d93ee22427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240831-095829'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036545c4-038e-4527-bdab-7d085f89ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2037dca-4fbb-4d80-a8bb-c2245d777ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rswarnka",
   "language": "python",
   "name": "rswarnka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
